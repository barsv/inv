{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import savgol_filter\n",
    "\n",
    "# Загружаем данные\n",
    "file_path = \"../npz/BTCUSD_1T.npz\"\n",
    "data = np.load(file_path, allow_pickle=True)\n",
    "if 'data' in data:\n",
    "    raw_data = data['data']\n",
    "else:\n",
    "    raise ValueError(\"Файл не содержит ключа 'data'\")\n",
    "columns = ['timestamp', 'open', 'high', 'low', 'close', 'volume']\n",
    "df = pd.DataFrame(raw_data, columns=columns)\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "df.set_index('timestamp', inplace=True)\n",
    "for col in ['open', 'high', 'low', 'close', 'volume']:\n",
    "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "# При необходимости можно ограничить число точек:\n",
    "#df = df.iloc[:50* 1000]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "def safe_round_index(value, grid_size):\n",
    "    \"\"\"\n",
    "    Округляет значение до ближайшего индекса в сетке [0, grid_size-1].\n",
    "    \n",
    "    :param value: вещественное число, которое надо перевести в индекс сетки.\n",
    "    :param grid_size: количество ячеек в сетке.\n",
    "    :return: округленный индекс, ограниченный диапазоном [0, grid_size-1].\n",
    "    \"\"\"\n",
    "    index = round(value)\n",
    "    return max(0, min(index, grid_size - 1))  # Ограничиваем диапазон\n",
    "\n",
    "\n",
    "########################################################################\n",
    "# Вспомогательная функция для перевода (x, y, z) в индексы сетки с использованием объекта grid_size\n",
    "def to_grid_3d(xx, yy, zz, bounds, grid_size):\n",
    "    \"\"\"\n",
    "    Преобразует координаты (xx, yy, zz) в индексы сетки.\n",
    "    \n",
    "    :param xx, yy, zz: координаты точки.\n",
    "    :param bounds: кортеж (x_min, x_max, y_min, y_max, z_min, z_max).\n",
    "    :param grid_size: словарь с ключами 'x', 'y', 'z' для размеров сетки.\n",
    "    :return: кортеж (i_x, i_y, i_z) – индексы точки в сетке.\n",
    "    \"\"\"\n",
    "    (x_min, x_max, y_min, y_max, z_min, z_max) = bounds\n",
    "    i_x = safe_round_index((xx - x_min) / (x_max - x_min) * (grid_size['x'] - 1), grid_size['x'])\n",
    "    i_y = safe_round_index((yy - y_min) / (y_max - y_min) * (grid_size['y'] - 1), grid_size['x'])\n",
    "    i_z = safe_round_index((zz - z_min) / (z_max - z_min) * (grid_size['z'] - 1), grid_size['x'])\n",
    "    # return (x_min + i_x * (grid_size['x'] - 1) / (x_max - x_min), i_y, i_z)\n",
    "    return (i_x, i_y, i_z)\n",
    "\n",
    "def weighted_percentile(values, weights, percentile):\n",
    "    \"\"\"\n",
    "    Вычисляет персентиль с учетом весов (вероятностей).\n",
    "    values - массив значений (сдвиги)\n",
    "    weights - соответствующие вероятности\n",
    "    percentile - персентиль (0-100)\n",
    "    \"\"\"\n",
    "    sorter = np.argsort(values)\n",
    "    values_sorted = np.array(values)[sorter]\n",
    "    weights_sorted = np.array(weights)[sorter]\n",
    "    weighted_cumsum = np.cumsum(weights_sorted)\n",
    "    weighted_cumsum /= weighted_cumsum[-1]  # нормируем, чтобы максимальная сумма была равна 1\n",
    "    return np.interp(percentile / 100, weighted_cumsum, values_sorted)\n",
    "\n",
    "def get_transitions(df, window_short, window_long, tau, grid_size):\n",
    "    \"\"\"\n",
    "    Разбивает фазовое пространство (x, y, z) на 3D-сетку и заполняет map переходов.\n",
    "    Здесь:\n",
    "      x = price_diff (0-я производная сглаженного относительного изменения цены)\n",
    "      y = первая производная (относительное изменение скорости)\n",
    "      z = вторая производная (ускорение изменения относительного изменения)\n",
    "    \n",
    "    :param df: DataFrame с ценами.\n",
    "    :param window_short: короткое окно сглаживания.\n",
    "    :param window_long: длинное окно сглаживания.\n",
    "    :param tau: шаг прогноза (в баров).\n",
    "    :param grid_size: словарь с размерами сетки, например {'x':50, 'y':50, 'z':50}.\n",
    "    :return: (cache, bounds), где\n",
    "             cache = { (i_x, i_y, i_z) -> { future_x: count } }\n",
    "             bounds = (x_min, x_max, y_min, y_max, z_min, z_max)\n",
    "    \"\"\"\n",
    "    polyorder = 3\n",
    "\n",
    "    # Сглаживаем цену\n",
    "    smoothed_short = savgol_filter(df['close'].values, window_short, polyorder)\n",
    "    smoothed_long  = savgol_filter(df['close'].values, window_long, polyorder)\n",
    "    \n",
    "    # Относительное изменение (в процентах)\n",
    "    rel_price_diff = (smoothed_short - smoothed_long) / smoothed_long\n",
    "\n",
    "    # Вычисляем три координаты: \n",
    "    # x = базовый сигнал (разность),\n",
    "    # y = первая производная,\n",
    "    # z = вторая производная.\n",
    "    x = savgol_filter(rel_price_diff, window_short, polyorder, deriv=0)\n",
    "    y = savgol_filter(rel_price_diff, window_short, polyorder, deriv=1)\n",
    "    z = savgol_filter(rel_price_diff, window_short, polyorder, deriv=2)\n",
    "    \n",
    "    # Границы фазового пространства\n",
    "    x_min, x_max = np.min(x), np.max(x)\n",
    "    y_min, y_max = np.min(y), np.max(y)\n",
    "    z_min, z_max = np.min(z), np.max(z)\n",
    "    bounds = (x_min, x_max, y_min, y_max, z_min, z_max)\n",
    "    \n",
    "    transitions = {}  # { (i_x, i_y, i_z) -> { future_x: count } }\n",
    "    n = len(x) - tau\n",
    "    for t in range(n):\n",
    "        cell_now = to_grid_3d(x[t], y[t], z[t], bounds, grid_size)\n",
    "        cell_future = to_grid_3d(x[t+tau], y[t+tau], z[t+tau], bounds, grid_size)\n",
    "        future_x = cell_future[0]  # Используем только x-компоненту будущей ячейки\n",
    "        if cell_now not in transitions:\n",
    "            transitions[cell_now] = {}\n",
    "        if future_x not in transitions[cell_now]:\n",
    "            transitions[cell_now][future_x] = 0\n",
    "        transitions[cell_now][future_x] += 1\n",
    "    # counts to probabilities\n",
    "    for cell_now in transitions:\n",
    "        cell_now_transitions = transitions[cell_now]\n",
    "        total = sum(cell_now_transitions.values())\n",
    "        for future_x in cell_now_transitions:\n",
    "            cell_now_transitions[future_x] /= total\n",
    "    return transitions, bounds\n",
    "\n",
    "########################################################################\n",
    "# Функция визуализации прогноза с использованием 3D-кэша (новый формат кеша)\n",
    "def plot_price_forecast_with_heatmap_3d(df, transitions, bounds, windows, tau, start_idx, end_idx, grid_size):\n",
    "    \"\"\"\n",
    "    Строит график цен и наносит прогноз в виде точек,\n",
    "    где цвет отражает частоту перехода. Для обратного прогнозирования используется только x-компонента из 3D-кэша.\n",
    "    \n",
    "    :param df: DataFrame с ценами (тестовая выборка).\n",
    "    :param transitions: [{}] transitions in phase space for each averaging window.\n",
    "    :param bounds: [(x_min, x_max, y_min, y_max, z_min, z_max)] – min,max values for the phase spaces.\n",
    "    :param windows: [(window_short, window_long)] window sizes that were used to build phase space.\n",
    "    :param tau: forecase distance.\n",
    "    :param start_idx: начало прогноза.\n",
    "    :param end_idx: конец прогноза.\n",
    "    :param grid_size: словарь с размерами сетки, например {'x':200, 'y':100, 'z':10}.\n",
    "    \"\"\"\n",
    "    polyorder = 3\n",
    "\n",
    "    # phase space coordinates for each window\n",
    "    xs = []\n",
    "    ys = []\n",
    "    zs = []\n",
    "    for w in range(len(windows)):\n",
    "        window_short, window_long = windows[w]\n",
    "        smoothed_short = savgol_filter(df['close'].values, window_short, polyorder)\n",
    "        smoothed_long  = savgol_filter(df['close'].values, window_long, polyorder)\n",
    "        rel_price_diff = (smoothed_short - smoothed_long) / smoothed_long\n",
    "        # calc phase space coordinates x, y, z\n",
    "        x = savgol_filter(rel_price_diff, window_short, polyorder, deriv=0)\n",
    "        y = savgol_filter(rel_price_diff, window_short, polyorder, deriv=1)\n",
    "        z = savgol_filter(rel_price_diff, window_short, polyorder, deriv=2)\n",
    "        # append coordinates in phase space for window w\n",
    "        xs.append(x)\n",
    "        ys.append(y)\n",
    "        zs.append(z)\n",
    "\n",
    "    # Используем ту же функцию to_grid_3d для преобразования\n",
    "    def to_grid(xx, yy, zz, bounds):\n",
    "        return to_grid_3d(xx, yy, zz, bounds, grid_size)\n",
    "\n",
    "    # тут дальше начинается сложное место.\n",
    "    # надо для каждого момента времени t взять прогнозы от разных маштабов (кешей) и объединить их.\n",
    "    # для этого:\n",
    "    # сделаем функцию, которая будет принимать на вход два прогноза и объединять их в один.\n",
    "    #    потом применять эту функцию к каждой паре прогнозов. но тут тоже есть проблема - как сохранять объедененные прогнозы.\n",
    "    #    если просто брать сдвиг цены одного маштбара, прибавлять к нему сдвиг цены другого масштаба и сохранять в \n",
    "    #    дикшенери, то такой дикшенери будет быстро расти в размере. например, если у нас 50 ячеек в каждом масштабе, а \n",
    "    #    масштабов 5 штук, то будет 50^5 ячеек = 312500000 ячеек. второй вариант - сразу посчитать разброс прогнозов и\n",
    "    #    сделать для него сетку. но сетку видимо придется делать с большим количеством ячеек, иначе округления прогнозов\n",
    "    #    на каждом слиянии будут давать слишком большие сдвиги.\n",
    "    def merge(forecasts1, x_ranges1, grid_size1, forecasts2, x_ranges2, grid_size2, result_x_ranges, result_grid_size):\n",
    "        (x_min1, x_max1) = x_ranges1\n",
    "        (x_min2, x_max2) = x_ranges2\n",
    "        (x_min, x_max) = result_x_ranges\n",
    "        result = {}\n",
    "        for (future_x1, probability1) in forecasts1.items():\n",
    "            for (future_x2, probability2) in forecasts2.items():\n",
    "                future_price_diff1 = x_min1 + (future_x1 / (grid_size1 - 1)) * (x_max1 - x_min1)\n",
    "                future_price_diff2 = x_min2 + (future_x2 / (grid_size2 - 1)) * (x_max2 - x_min2)\n",
    "                future_price_diff = future_price_diff1 + future_price_diff2\n",
    "                future_x = safe_round_index((future_price_diff - x_min) / (x_max - x_min) * (result_grid_size - 1), result_grid_size)\n",
    "                probability = probability1 * probability2\n",
    "                if future_x not in result:\n",
    "                    result[future_x] = 0\n",
    "                result[future_x] += probability\n",
    "        return result\n",
    "\n",
    "    future_points = []\n",
    "    forecast_stats = []\n",
    "    N = len(x)\n",
    "    (x_min, x_max) = (0, 0)\n",
    "    for w in range(len(windows)):\n",
    "        (x_min_w, x_max_w, _, _, _, _) = bounds[w]\n",
    "        # just sum mins and maxes because if for window 1 min movement was x_min1 and for window 2 min movement was x_min2\n",
    "        # then for merged window min movement will be x_min1+x_min2. Note x_min1 and x_min2 can be negative and most probably will be.\n",
    "        x_min += x_min_w\n",
    "        x_max += x_max_w\n",
    "    result_grid_size = 200\n",
    "    for t in range(start_idx, min(end_idx, N - tau)):\n",
    "        total_transitions = {}\n",
    "        total_transitions[safe_round_index((result_grid_size - 1)*(0 - x_min)/(x_max - x_min), result_grid_size)] = 1\n",
    "        for w in range(len(windows)):\n",
    "            x, y, z = xs[w], ys[w], zs[w]\n",
    "            w_bounds = bounds[w]\n",
    "            cell_now = to_grid(x[t], y[t], z[t], w_bounds)\n",
    "            (x_min_w, x_max_w, _, _, _, _) = w_bounds\n",
    "            w_transitions = transitions[w]\n",
    "            if cell_now in w_transitions:\n",
    "                cell_now_transitions = w_transitions[cell_now]\n",
    "                total_transitions = merge(total_transitions, (x_min, x_max), result_grid_size, cell_now_transitions, (x_min_w, x_max_w), grid_size['x'], (x_min, x_max), result_grid_size)\n",
    "        max_prob = 0\n",
    "        max_prob_shift = 0\n",
    "        abs_future_price_diffs_probs = []\n",
    "        for future_x, prob in total_transitions.items():\n",
    "            # Обратное преобразование: переводим future_x обратно в значение x\n",
    "            # reverse transformation: index in the grid future_x into price delta movement future_price_diff\n",
    "            future_price_diff = x_min + (future_x / (result_grid_size - 1)) * (x_max - x_min)\n",
    "            # rough hypothesis for forecast: future_price_diff for the largest window will be close to zero, \n",
    "            # hence we can just add the price change to the current df['close'].\n",
    "            # future_price_diff is measured in relative price change, \n",
    "            # so we need to multiply it by smoothed_long[t] to get the future price.\n",
    "            future_price = future_price_diff * smoothed_long[t] + df['close'].iloc[t]\n",
    "            current_time = df.index[t]\n",
    "            abs_future_price_diff = future_price_diff * smoothed_long[t]\n",
    "            abs_future_price_diffs_probs.append((abs_future_price_diff, prob))\n",
    "            future_points.append((current_time, future_price, abs_future_price_diff, prob))\n",
    "            if prob > max_prob:\n",
    "                max_prob = prob\n",
    "                max_prob_shift = future_price_diff\n",
    "        abs_future_price_diffs, abs_future_price_probs = zip(*abs_future_price_diffs_probs)\n",
    "        weighted_mean_shift = np.sum(np.array(abs_future_price_diffs) * np.array(abs_future_price_probs)) / np.sum(abs_future_price_probs)\n",
    "        middle = (np.max(abs_future_price_diffs) + np.min(abs_future_price_diffs)) / 2\n",
    "        forecast_stats.append((max_prob_shift * smoothed_long[t],\n",
    "                                weighted_percentile(abs_future_price_diffs, abs_future_price_probs, 25),\n",
    "                                weighted_percentile(abs_future_price_diffs, abs_future_price_probs, 50),\n",
    "                                weighted_percentile(abs_future_price_diffs, abs_future_price_probs, 75),\n",
    "                                weighted_mean_shift,\n",
    "                                middle))\n",
    "\n",
    "    fig, (ax, ax2) = plt.subplots(\n",
    "        2,  # Два графика (2 строки)\n",
    "        1,  # Один столбец\n",
    "        figsize=(14, 7),  # Общий размер\n",
    "        gridspec_kw={'height_ratios': [2, 5]}\n",
    "    )\n",
    "    times = df.index[start_idx:end_idx]\n",
    "    ax.plot(times, df['close'].iloc[start_idx:end_idx], label=\"Цена BTC/USD\", color='black')\n",
    "    ax.plot(times, df['close'].shift(-tau).iloc[start_idx:end_idx], label=\"Цена (tau вперед)\", color='blue')\n",
    "    ax2.plot(times, (df['close'].shift(-tau) - df['close'])[start_idx:end_idx], label=\"price diff\", color='red')\n",
    "    max_prob_shifts, percentile_25, percentile_50, percentile_75, weighted_mean_shifts, middles = zip(*forecast_stats)\n",
    "    ax2.plot(times, max_prob_shifts, label=\"max prob shifts\", color='blue')\n",
    "    #ax2.plot(times, percentile_25, label=\"percentile_25\", color='green')\n",
    "    #ax2.plot(times, percentile_50, label=\"percentile_50\", color='green')\n",
    "    #ax2.plot(times, percentile_75, label=\"percentile_75\", color='green')\n",
    "    ax2.plot(times, weighted_mean_shifts, label=\"weighted_mean_shifts\", color='green')\n",
    "    ax2.plot(times, middles, label=\"middles\", color='orange')\n",
    "    # add zero line to ax2\n",
    "    ax2.axhline(y=0, color='black', linestyle='--', alpha=0.5)\n",
    "    if future_points:\n",
    "        future_times, future_prices, future_diffs, future_probs = zip(*future_points)\n",
    "        # Создаём одноцветный красный градиент от светлого к насыщенному\n",
    "        red_gradient = LinearSegmentedColormap.from_list(\"red_gradient\", [\"#FFEEEE\", \"#FF0000\"])\n",
    "        ax.scatter(future_times, future_prices, c=future_probs, cmap=red_gradient, alpha=0.5, s=19)\n",
    "        ax2.scatter(future_times, future_diffs, c=future_probs, cmap=red_gradient, alpha=0.5, s=19)\n",
    "    import matplotlib.dates as mdates\n",
    "    ax.format_coord = lambda x, y: f'x={mdates.num2date(x).strftime(\"%m-%d %H:%M\")}, y={y:.2f}'\n",
    "    ax2.format_coord = lambda x, y: f'x={mdates.num2date(x).strftime(\"%m-%d %H:%M\")}, y={y:.2f}'\n",
    "    ax.legend()\n",
    "    ax2.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Пример: разделим данные на train/test (80/20)\n",
    "train_size = int(0.8 * len(df))\n",
    "train_df = df.iloc[:train_size]\n",
    "test_df  = df.iloc[train_size:]\n",
    "\n",
    "grid_size = {'x': 50, 'y': 20, 'z': 10}\n",
    "tau = 10\n",
    "\n",
    "caches = []\n",
    "bounds = []\n",
    "windows = []\n",
    "\n",
    "window_short = 31\n",
    "window_long  = 61\n",
    "cache_3d, bounds_3d = get_transitions(train_df, window_short, window_long, tau, grid_size)\n",
    "caches.append(cache_3d)\n",
    "bounds.append(bounds_3d)\n",
    "windows.append((window_short, window_long))\n",
    "\n",
    "window_short = 61\n",
    "window_long  = 121\n",
    "cache_3d, bounds_3d = get_transitions(train_df, window_short, window_long, tau, grid_size)\n",
    "caches.append(cache_3d)\n",
    "bounds.append(bounds_3d)\n",
    "windows.append((window_short, window_long))\n",
    "\n",
    "# window_short = 121\n",
    "# window_long  = 241\n",
    "# cache_3d, bounds_3d = get_transitions(train_df, window_short, window_long, tau, grid_size)\n",
    "# caches.append(cache_3d)\n",
    "# bounds.append(bounds_3d)\n",
    "# windows.append((window_short, window_long))\n",
    "\n",
    "# window_short = 241\n",
    "# window_long  = 481\n",
    "# cache_3d, bounds_3d = get_transitions(train_df, window_short, window_long, tau, grid_size)\n",
    "# caches.append(cache_3d)\n",
    "# bounds.append(bounds_3d)\n",
    "# windows.append((window_short, window_long))\n",
    "\n",
    "start_idx=window_long + 1300\n",
    "end_idx=window_long + 1300 + 300\n",
    "plot_price_forecast_with_heatmap_3d(test_df, caches, bounds, windows, tau, start_idx, end_idx, grid_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_short = 61\n",
    "window_long  = 121\n",
    "cache_3d, bounds_3d = build_phase_space_grid_3d(train_df, window_short, window_long, tau, grid_size)\n",
    "start_idx=window_long\n",
    "end_idx=window_long + 300\n",
    "plot_price_forecast_with_heatmap_3d(test_df, cache_3d, bounds_3d, window_short, window_long, tau, start_idx, end_idx, grid_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_short = 121\n",
    "window_long  = 241\n",
    "print(f\"tau={tau}\")\n",
    "cache_3d, bounds_3d = build_phase_space_grid_3d(train_df, window_short, window_long, tau, grid_size)\n",
    "start_idx=window_long\n",
    "end_idx=window_long + 300\n",
    "plot_price_forecast_with_heatmap_3d(test_df, cache_3d, bounds_3d, window_short, window_long, tau, start_idx, end_idx, grid_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_short = 241\n",
    "window_long  = 481\n",
    "cache_3d, bounds_3d = build_phase_space_grid_3d(train_df, window_short, window_long, tau, grid_size)\n",
    "start_idx=window_long\n",
    "end_idx=window_long + 1300\n",
    "plot_price_forecast_with_heatmap_3d(test_df, cache_3d, bounds_3d, window_short, window_long, tau, start_idx, end_idx, grid_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_short = 481\n",
    "window_long  = 480*2+1\n",
    "cache_3d, bounds_3d = build_phase_space_grid_3d(train_df, window_short, window_long, tau, grid_size)\n",
    "start_idx=window_long\n",
    "end_idx=window_long + 3000\n",
    "plot_price_forecast_with_heatmap_3d(test_df, cache_3d, bounds_3d, window_short, window_long, tau, start_idx, end_idx, grid_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tau = 150\n",
    "window_short = 481\n",
    "window_long  = 480*2+1\n",
    "cache_3d, bounds_3d = build_phase_space_grid_3d(train_df, window_short, window_long, tau, grid_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shift = window_long + 2500\n",
    "start_idx=shift\n",
    "end_idx=shift+3000\n",
    "plot_price_forecast_with_heatmap_3d(test_df, cache_3d, bounds_3d, window_short, window_long, tau, start_idx, end_idx, grid_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
